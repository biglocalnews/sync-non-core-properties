{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc41a2-cb37-4a6e-8113-0462d7757b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bln import Client\n",
    "from pyquery import PyQuery as pq\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "from glob import glob\n",
    "import datetime\n",
    "import os\n",
    "import socket\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f2b08-bedf-4bbe-b4f5-73deadf22745",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now(datetime.timezone.utc).strftime(\"%Y-%m-%dT%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2736b-26fa-442b-9413-4c83dcc08b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmldir = \"html/\"\n",
    "csvdir = \"csv/\"\n",
    "\n",
    "for localdir in [htmldir, csvdir]:\n",
    "    os.makedirs(localdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c10b9-1b92-48f8-a7ee-229a8448d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out whether we should be syncing to Big Local News server\n",
    "def in_production():\n",
    "    if 'GITHUB_RUN_ID' in os.environ or socket.gethostname() in [\"mikelight\", \"racknerd-26f61a\"]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b8346-3aaf-4a9b-b44b-8701dbff4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosturl = \"https://www.gsa.gov/real-estate/real-estate-services/real-property-disposition/noncore-property-list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395ab54-90ae-496e-a210-533400c1b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(hosturl)\n",
    "if not r.ok:\n",
    "    print(f\"Failure to download file! What did you do?\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    with open(f\"{htmldir}noncore_{timestamp}.html\", \"wb\") as outfile:\n",
    "        outfile.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90375cdd-9a01-41bc-bc57-70d86731e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_production:\n",
    "    bln_api = os.environ[\"BLN_API_TOKEN\"]\n",
    "    bln = Client(bln_api)\n",
    "    project = bln.get_project_by_name(\"GSA non-core properties\")\n",
    "    project_id = project['id']\n",
    "\n",
    "    # Get all the files in the project.\n",
    "    archived_files = {}\n",
    "    for f in project['files']:\n",
    "        archived_files[f['name']] = f['updatedAt']\n",
    "    print(f\"{len(archived_files):,} archived files found.\")\n",
    "\n",
    "    rawlocalhtmls = glob(htmldir + \"*.html\")\n",
    "    additions = []\n",
    "    localhtmls = []\n",
    "    for rawlocalhtml in rawlocalhtmls:\n",
    "        basefilename = rawlocalhtml.replace(\"\\\\\", \"/\").replace(htmldir, \"\")\n",
    "        localhtmls.append(basefilename)\n",
    "        if basefilename not in archived_files:\n",
    "            additions.append(basefilename)\n",
    "    print(f\"{len(additions):,} files need to be archived.\")\n",
    "    for addition in tqdm(additions):\n",
    "        sourcefilename = htmldir + addition\n",
    "        bln.upload_file(project_id, sourcefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73316bd2-b8ae-4bb3-9974-8da3eb8d5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawlocalcsvs = glob(csvdir + \"*.csv\")\n",
    "localcsvs = []\n",
    "for rawlocalcsv in rawlocalcsvs:\n",
    "    localcsvs.append(rawlocalcsv.replace(\"\\\\\", \"/\").replace(csvdir, \"\"))\n",
    "\n",
    "rawlocalhtmls = glob(htmldir + \"*.html\")\n",
    "if in_production():\n",
    "    to_upload = []\n",
    "\n",
    "to_convert = {}\n",
    "for rawlocalhtml in rawlocalhtmls:\n",
    "    basehtml = rawlocalhtml.replace(\"\\\\\", \"/\").replace(htmldir, \"\")\n",
    "    basecsv = basehtml.replace(\".html\", \".csv\")\n",
    "    if basecsv not in localcsvs:\n",
    "        to_convert[basehtml] = basecsv\n",
    "    if in_production():\n",
    "        if basecsv not in archived_files:\n",
    "            to_upload.append(basecsv)\n",
    "print(f\"{len(to_convert):,} files need to be converted from HTML to CSV.\")\n",
    "if in_production:\n",
    "    print(f\"{len(to_upload)} of those CSVs should be uploaded later.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526a8d3-b5d6-4a3f-9c7f-e002e4a39d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for htmlfile in to_convert:\n",
    "    csvfile = to_convert[htmlfile]\n",
    "    with open(htmldir + htmlfile, \"r\", encoding=\"utf-8\") as infile:\n",
    "        html = infile.read()\n",
    "    try:\n",
    "        if \"scrollTable_search\" in html:\n",
    "            mastertable = pq(html)(\"table.scrollTable_search\")[0]\n",
    "        elif \"usa-table\" in html:\n",
    "            mastertable = pq(html)(\"table.usa-table\")[0]\n",
    "        else:\n",
    "            masterable = None\n",
    "        \n",
    "        headerrow = pq(mastertable)(\"tr\")[0]\n",
    "        headers = []\n",
    "        for item in pq(headerrow)(\"th\"):\n",
    "            headers.append(pq(item).text().strip())\n",
    "    \n",
    "        masterlist = []\n",
    "        for row in pq(mastertable)(\"tr\")[1:]:    # Skip header row\n",
    "            line = {}\n",
    "            for i in range(0, len(headers)):\n",
    "                line[headers[i]] = pq(pq(row)(\"td\")[i]).text().strip()\n",
    "            masterlist.append(line)\n",
    "    \n",
    "        with open(csvdir + csvfile, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "            print(f\"Trying to do {csvfile}\") \n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(headers)\n",
    "            for row in masterlist:\n",
    "                writer.writerow(list(row.values()))\n",
    "    except IndexError:\n",
    "        print(f\"Error on {htmlfile}: They broke the table format, or removed it altogether.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdf17d-aa85-4476-8a09-ead90ade0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_production:\n",
    "    for csvfile in to_upload:\n",
    "        bln.upload_file(project_id, csvdir + csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36007432-146f-4e5c-89db-14426f42f561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a078de-ec33-47ad-965d-4d8b5f0d76f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
